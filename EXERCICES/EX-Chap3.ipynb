{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Exercise\"></a>\n",
    "\n",
    "### Exercises\n",
    "\n",
    "#### CRUD operations\n",
    "\n",
    "Create a new db name Todo and a new collection named \"CRUD_exercise\" and do the following:\n",
    "\n",
    "**TODO 1**: Take the dict created in the TODO 4 in chapter I and save it in the collection \"CRUD_exercise\".\n",
    "\n",
    "**TODO 2**: Insert 3 documents with key = x and values = 1, delete one of them. Which one is deleted first ? the most recent or oldest one ? increment the value of x to 4.\n",
    "\n",
    "**TODO 3**: Insert the dict created in the TODO 6 Chapter I in the example collection.\n",
    "\n",
    "**TODO 4**: Get documents where authors key exist in the collection \"CRUD_exercise\".\n",
    "\n",
    "**TODO 5**: Change the documents where x = 4 to x = 1.\n",
    "\n",
    "**TODO 6**: Find documents where author is not_mike and set author as real_mike.\n",
    "\n",
    "**TODO 7**: Delete documents where author is real_mike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['Todo']\n",
    "collection = db['CRUD_exercise']\n",
    "print(\"Database and Collection Created: \", db.name, collection.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 1**: Take the dict created in the TODO 4 in chapter I and save it in the collection \"CRUD_exercise\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('/Users/valen/Desktop/SAS/BC.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM tomatch3\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "data = [{'id': row[0], 'rdm_float': row[1]} for row in rows]\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into MongoDB collection: CRUD_exercise\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to the MongoDB server\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['Todo']\n",
    "collection = db['CRUD_exercise']\n",
    "\n",
    "# Insert data into MongoDB\n",
    "collection.insert_many(data)\n",
    "\n",
    "# Verify insertion\n",
    "print(collection.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 2**: Insert 3 documents with key = x and values = 1, delete one of them. Which one is deleted first ? the most recent or oldest one ? increment the value of x to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted document IDs: [ObjectId('6630ee93e01c5a30842e1678'), ObjectId('6630ee93e01c5a30842e1679'), ObjectId('6630ee93e01c5a30842e167a')]\n"
     ]
    }
   ],
   "source": [
    "#Insert 3 documents with key = x and values = 1\n",
    "docs = [{'x': 1}, {'x': 1}, {'x': 1}]\n",
    "insert_result = collection.insert_many(docs)\n",
    "print(f\"Inserted document IDs: {insert_result.inserted_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted count: 1\n"
     ]
    }
   ],
   "source": [
    "#delete one of them\n",
    "delete_result = collection.delete_one({'x': 1})\n",
    "print(f\"Deleted count: {delete_result.deleted_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MongoDB ne va pas prendre en compte le plus récent ou plus ancien des documents mais supprimer le premier qu'il rencontre ayant la caractéristique demandé, dans notre cas, nous avons trois documents \"{'x': 1}\", donc il va en supprimer un au hasard s'il n'y a pas plus de spécification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated count: 1\n"
     ]
    }
   ],
   "source": [
    "#increment the value of x to 4\n",
    "update_result = collection.update_one({'x': 1}, {'$set': {'x': 4}})\n",
    "print(f\"Updated count: {update_result.modified_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 3**: Insert the dict created in the TODO 6 Chapter I in the example collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('/Users/valen/Desktop/SAS/BC.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM NN\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "dataNN = [{'id': row[0], 'rdm_float': row[1]} for row in rows]\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into MongoDB collection: CRUD_exercise\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['Todo']\n",
    "collection = db['CRUD_exercise']\n",
    "\n",
    "collection.insert_many(dataNN)\n",
    "\n",
    "print(collection.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 4**: Get documents where authors key exist in the collection \"CRUD_exercise\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = collection.find({'authors': {'$exists': True}})\n",
    "\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**TODO 5**: Change the documents where x = 4 to x = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult({'n': 0, 'nModified': 0, 'ok': 1.0, 'updatedExisting': False}, acknowledged=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.update_many({'x': 4}, {'$set': {'x': 1}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**TODO 6**: Find documents where author is not_mike and set author as real_mike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult({'n': 0, 'nModified': 0, 'ok': 1.0, 'updatedExisting': False}, acknowledged=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.update_many({'author': 'not_mike'}, {'$set': {'author': 'real_mike'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**TODO 7**: Delete documents where author is real_mike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResult({'n': 0, 'ok': 1.0}, acknowledged=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.delete_many({'author': 'real_mike'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Managing DB\n",
    "\n",
    "**TODO 8**: create a collection named \"CRUD_exercise_benchmark\" with 500k observations, ids increment of 2 (sequence:0,2,4,6,...1M). Give a random np.array with a key named \"values\" and use the insert_many. Then create an index on the id and benchmark queries before and after indexing. Did the index help ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
      "Traceback (most recent call last):\n",
      "  File \"zmq\\\\backend\\\\cython\\\\checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 500000 doc.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "start_time_with_index = time.time()\n",
    "doc = [{'id': i, 'values': np.random.rand(10).tolist()} for i in range(0, 1000000, 2)]\n",
    "\n",
    "insert_result = collection.insert_many(doc)\n",
    "end_time_no_index = time.time()\n",
    "print(f\"Inserted {len(insert_result.inserted_ids)} doc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "start_time_with_index = time.time()\n",
    "collection.create_index([('id', pymongo.ASCENDING)])\n",
    "end_time_with_index = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sans index: 101.88962388038635 seconds.\n",
      "Avec index: 0.0010027885437011719 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sans index: {end_time_no_index - start_time_no_index} seconds.\")\n",
    "print(f\"Avec index: {end_time_with_index - start_time_with_index} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oui, nous remarquons que la requête sans index mets beaucoup plus de temps que la requête avec index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 9**: create a random collection in a random db and put the new collection in the tutorial DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into zwroewvwme.erqrbfzety\n",
      "Data copied to tutorial.erqrbfzety\n",
      "Database zwroewvwme deleted\n",
      "Collections in 'tutorial' database: ['image', 'benchmark_2', 'example', 'benchmark', 'arxiv_api', 'erqrbfzety', 'example_to_dump']\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "import string\n",
    "import random\n",
    "\n",
    "def random_string(length=10):\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(length))\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "\n",
    "random_db_name = random_string()\n",
    "random_col_name = random_string()\n",
    "\n",
    "random_db = client[random_db_name]\n",
    "random_collection = random_db[random_col_name]\n",
    "\n",
    "documents = [{'id': i, 'values': np.random.rand(10).tolist()} for i in range(10)]\n",
    "random_collection.insert_many(documents)\n",
    "print(f\"Data inserted into {random_db_name}.{random_col_name}\")\n",
    "\n",
    "tutorial_db = client['tutorial']\n",
    "tutorial_collection = tutorial_db[random_col_name]\n",
    "\n",
    "data_to_transfer = list(random_collection.find({}))\n",
    "tutorial_collection.insert_many(data_to_transfer)\n",
    "print(f\"Data copied to tutorial.{random_col_name}\")\n",
    "\n",
    "client.drop_database(random_db_name)\n",
    "print(f\"Database {random_db_name} deleted\")\n",
    "\n",
    "print(\"Collections in 'tutorial' database:\", tutorial_db.list_collection_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 10**: What is the difference between an inner join and an outer join ? Is the query seen during course an inner or outer join ? Play with the query to show all the joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real world problems\n",
    "\n",
    "**TODO 11**:  Use the oaipmh and api code get papers after January 2020 and for \"cs,math,econ\" categories. Insert them in MongoDB. Import only the first 200. How is it sorted ? How can you define your own sort()? Query papers to get papers after 2021, which have 3 authors and with domain \"cs\".\n",
    "\n",
    "**TODO 12**: Do the same as TODO 8 but with the connection to the cluster. Then check the metrics and take screenshot of opcounters, logical size and connections.\n",
    "\n",
    "**TODO 13**: Download a random image and store it in a collection.\n",
    "\n",
    "**TODO 14**: Try to store a pandas dataframe in mongoDB (array with rownames, array with colnames and matrix with values)\n",
    "\n",
    "**TODO 15**: Insert the movie_review.tsv data into mongodb. Then query it to find the number of review that are positive and negative review. Fetch the docs which have \"unexpected\" in their review, how many are they ? Think of a clever way to count the number of words in the review using MongoDB (hint: Transform the review text before the insert in MongoDB) and create a density of number of words per review.\n",
    "\n",
    "**TODO 16**: Download a [sound sample](https://freesound.org/browse/). Try to store it in MongoDB \n",
    "\n",
    "**TODO 17**: Create a collection with 30M observation with a single key : \"year\" which is a random value between 2000-2020. Get documents with year = 2000. Does using an index helps ? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
